- [9.1 经典参数估计](#91-经典参数估计)
  - [9.1.1 估计量的性质](#911-估计量的性质)
  - [9.1.2 置信区间](#912-置信区间)
  - [9.1.3 最大似然估计（Maximum Likelihood estimation)](#913-最大似然估计maximum-likelihood-estimation)

### 9.1 经典参数估计

统计推断是从观测数据推断未知变量或未知模型的有关信息的过程。在统计领域有两种突出但对立的思想学派：贝叶斯学派和经典学派。贝叶斯学派在统计推断过程中将未知量看作 $\Theta$，即随机变量；经典学派在统计推断过程中将未知变量看作一个常数 $\theta$。接下来介绍经典学派的统计推断的框架。

<img src='./img/图9-1 经典统计推断框架.png' />

从上图中可以看出，对试验进行观察得到随机变量 $X$，该随机变量是从含有未知量 $\theta$ 的分布中得到的，所以 $X$ 受该未知量的影响。我们想要知道 $\theta$ 的值，换言之，就是我们想知道数据来自哪个分布；我们的做法是取一些观测到的值然后对其进行处理，处理完之后得到评估器（estimator）。什么是评估器？取数据，然后得到一个与数据相关的函数，这就是数据处理的意义，这个函数就是 $\widehat{\Theta}$ ，即评估器。

$\widehat{\Theta}$ 是随机变量的函数，因此它本身也是一个随机变量，这也是为什么用大写字母表示它的原因。对于 $x$ 经过评估器的处理可以得到一个特定值 $\theta$，我们称其为评估值。对于随机变量，我们需要注意区别其本身和随机变量的取值，类似的，评估器为随机变量，它是对如何生成评估值的描述；评估器的值为评估值，它是随机变量的值。

当 $X$ 和 $\theta$ 是多维时，我们也有类似的框架。$p_X(x:\theta)$ 不是条件分布，因为 $\theta$ 不是随机变量，它只是一个普通的分布，只是其中恰巧涉及一些参数。从数学上思考这个框架的最佳方式是，我们本质上是在处理多个候选的模型，比如上图中的红蓝两条曲线就可看作两个候选的模型，每一种模型对应一个可能的 $\theta$；当我们观察到的数据大部分都落在蓝色曲线下方时，我们就可以推断，这些数据几乎不可能来自红色曲线的分布并且有很大可能来自蓝色曲线的分布。因此，即使我们没有将 $\theta$ 看作随机变量，也没有使用贝叶斯法则，至少从这个例子中可以看出我们的推断是合理的。

接下来对经典统计中可能遇到的不同类型的问题进行讨论。

<img src='./img/图9-2 经典统计推断说明.png' />

一种类型是假设检验问题。它要求我们在两个候选的模型之间进行选择，即从两个 $\theta$ 中进行选择。想象一台生产硬币的机器，生产出的硬币要么是公平的要么是有特定的偏差，你可以抛几次硬币，然后判断该硬币是哪种类型的。

还有一种类型的假设检验问题，它要求我们在多个候选的模型之间进行选择。与上面生产硬币的例子类似，假设生产出的硬币要么是公平的要么是不公平的，需要注意的是，不公平的硬币中包括很多种类型，本书中并不会涉及这种问题。

另一种类型是估计问题。在估计问题中 $\theta$ 要么是连续的要么可以从许多值中选一个，我们的目的是设计一个评估器来得到好的估计值。好的标准是什么？估计值和真实值尽可能接近。可以用各种各样的方法来让它们尽可能接近，因此，评估器的设计没有单一的方法，这在经典统计中很常见，通常问题不存在单一的最佳方法；而在贝叶斯中是用一种完全明确的方式进行推断。

#### 9.1.1 估计量的性质

接下来考虑一个最简单的估计问题——估计一个确定分布的随机变量的期望并通过这个例子介绍一些相关术语以及估计量的相关性质。

<img src='./img/图9-3 估计量的性质例子.png' />

如图所示，假设我们有一系列的 $i.i.d$ 的随机变量，期望为 $\theta$，方差为 $\sigma^2$，$\theta$ 为未知量，我们需要估计它的值。最自然的估计方法就是用这一系列的观察值形成一个样本均值，然后进行计算。接下来讨论一些这个评估器的一些性质。

首先，这个评估器的期望等于真实的期望，并且这个性质对所有的 $\theta$ 都成立，我们称 $\widehat{\Theta}$ 是无偏 的。

第二，由 $WLLN$ 可得样本均值依概率收敛于真实均值，无论 $\theta$ 为何值，都有这个性质成立，因此，我们称 $\widehat{\Theta}$ 为 $\theta$ 的相合估计序列。

最后，如何计算估计误差的大小？我们一般用均方误差进行估计，由上图可得，本例中的均方误差为样本均值的方差，误差随着 $n$ 的增大而减小，此时的均方误差与 $\theta$ 无关，但在其它例子中，有可能会得到一个与 $\theta$ 相关的函数。

接下来讨论一下均方误差，均方误差可以用于任意的评估器上。我们可以将均方误差分解为评估器的方差加上误差的平方，即 $\text{var} (\widehat{\Theta}) + (\text{bias})^2$，其中 $bias = E[\widehat{\Theta} - \theta]$。下面是两个具体的例子：

<img src='./img/图9-4 均方误差理解.png' />

从上图可以看出，我们无法说明哪个评估器比较好，但对于第一个评估器来说，当 $n\to\infin$ 时，我们可以得到真实的均值，这了零评估器所不具备的；如果 $n$ 适中，两者都不具备这种性质，如果我们有充分的理由确定真实均值的取值在 $0$ 的附近，那么零评估器更好，因为它可以得到更小的均方误差。

回到均方误差的公式，评估器的方差在均方误差中扮演者一个重要的角色，它的更直观的一个变体是评估器的标准差。标准差越大，意味着该评估器的估计值越不可行，越小则相反。除了设计和实现评估器外，人们还会寻找方法来计算与之相关的标准差。

#### 9.1.2 置信区间

评估器的值无法提供足够的信息，还需要提供标准误差或置信区间。下面通过一个故事介绍置信区间：

假设你在一家民调公司工作，你进行了一项民意调查，然后向你的老板报告：我得到了一个估计值。然后你的老板问你的估计结果准确吗，然后你回到工位进行计算，之后告诉你的老板这个估计值的置信区间为 $95\%$，范围在 $[0.3,0.52]$ 之间，老板说：看起来不错，不过这个置信区间意味着什么呢？然后你打开课本查找置信区间的定义，置信区间为 $95\%$ 意味着 $P(\widehat{\Theta}^-\leqslant\theta\leqslant\widehat{\Theta}^+\geqslant 95\%$，然后你的老板召开发布会说，该民调的真实值在 $[0.3,0.52]$ 之间的概率至少为 $95\%$。

<img src='./img/图9-5 置信区间概念.png'>

上面的结论实际上是错误的，这是对置信区间最常见的误解，置信区间为 $95\%$ 时，我们不能说 $\theta$ 落在 $[0.3, 0.52]$ 之间的概率为 $95\%$，因为这种表述不包含任何随机变量，在经典统计方法中，$\theta$ 是一个常数，实际上，“真实参数落在置信区间” 中的随机项是置信区间而不是真实参数($\theta$)，即置信区间有 $95\%$ 的概率可以捕获到真实参数。那么如何得到置信区间呢？最常见的方法是基于正态近似。下面是一个例子：

<img src='./img/图9-6 置信区间的求法.png'>

以估计某个变量的均值为例，通过观察得到一系列 $i.i.d$ 的随机变量，然后使用样本均值作为评估器。假设我们要构造一个 $95\%$ 的置信区间，由 $CLT$ 可得，可用标准正态对其分布进行近似，要使置信区间为 $95\%$，即，
$$
P\left(\frac{\left| \widehat{\Theta}_n - \theta\right|}{\sigma/\sqrt{n}}\leqslant a\right) \approx 0.95\rArr 2\Phi(a)-1\approx 0.95\rArr a=1.96,\\[2ex]
P\left(\widehat{\Theta}_n - \frac{1.96\sigma }{\sqrt{n}}\leqslant \theta\leqslant\widehat{\Theta}_n + \frac{1.96\sigma }{\sqrt{n}}\right) \approx 0.95
$$
由此可得 $95\%$ 置信区间。为了求出上述置信区间的端点，我们需要知道 $\sigma$ 的值，即标准差，如果题目中没有给出标准差，那么我们如何求端点值？

第一种方法是使用 $\sigma$ 的上界来代替 $\sigma$，这是一种比较保守的方法，它会使置信区间的间隔比之前更大。

第二种方法是使用适合当前 $\sigma$ 的方法对其进行估计。图中有例子。

以上两个都是对特定的情况进行估计，更一般的方法是使用样本均值的方差对其进行估计。对于一系列 $i.i.d$ 的观察值，由方差的公式可得 $\sigma^2 = E[(X_i-\theta)^2]$，由 $WLLN$ 可得，$\frac1n\sum_{i=1}^n(X_i-\theta)^2$ 依概率收敛于 $E[(X_i-\theta)^2]$ 即 $\sigma^2$；因为我们不知道 $\theta$ 的值，所以使用  $\widehat{\Theta}_n$ 代替 $\theta$，即 $\frac1n\sum_{i=1}^n(X_i-\widehat{\Theta}_n)^2$ 该值也依概率收敛于 $\sigma^2$，因为 $\widehat{\Theta}_n$ 依概率收敛于 $\theta$。

<img src='./img/图9-7 sigma未知时的置信区间.png' />

构造置信区间的过程涉及两个近似，一个是根据 $CLT$ 样本均值的分布近似标准正态的分布；另一个是对 $\sigma$ 的估计。这两个近似过程引入了一些随机性，会导致置信区间的间隔比原来的要大，我们可以通过 $t-$分布 对其进行修正，当 $n$ 很小时一般会使用 $t-$分布进行修正，但是当 $n$ 很大时 $t-$ 分布与正态分布非常相似，因此可以直接使用正态分布。

另一种估计方差的方法是使用 $\frac{1}{n-1}\sum_{i=1}^n(X_i-\widehat{\Theta}_n)^2$ 而不是 $\frac1n\sum_{i=1}^n(X_i-\widehat{\Theta}_n)^2$ 因为前者是无偏估计量，另一方面，当 $n$ 很大时，这两者其实是没有区别的。

<img src='./img/图9-8 其它变量的自然的评估方法.png'/>

#### 9.1.3 最大似然估计（Maximum Likelihood estimation)

如果未知参数可以表示成期望的样子，根据上面的例子我们可以使用样本均值对其进行估计；如果未知参数无法表示成期望的样子，那么该如何估计呢？通过找到使观察值出现的可能性最大的 $\theta$ 来对真实的未知数进行估计，这就是最大似然估计的基本思想。

<img src='./img/图9-9 最大似然估计思想.png' />

最大似然估计的一些性质：

<img src='./img/图9-9 最大似然估计思想.png' />

我们需要计算给定 $\theta$ 下观测数据出现的概率，这是一个 $\theta$ 的函数，我们需要找到这个函数的最大值。

如果 $X_i$ 是取自 $p_X(x:\theta)$ 的 $i.i.d$ 的随机变量，那么，在某些合适的假定条件下，最大似然估计的每个分量都具有相合性且渐进正态。利用上述的渐进正态，通过分析和模拟的方法可以求得标准差，通过标准差可求得置信区间。

<img src='./img/图9-11 最大似然估计例子1.png' />

<img src='./img/图9-12 最大似然估计例子2.png' />